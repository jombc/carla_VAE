# Vision based End-to-end autonomous driving using Cycle-consistent VAE
The vision based end-to-end autonomous driving framework for CARLA 0.8.4 benchmarks.
The framework has two sub-modules
 1. Disentanglement_VAE: To disentangling domain-specific feature and domain-general feature from pair images using Cycle-consistent VAE.
 2. starlab_2022: To predict the action values to drive an ego-vehicle to the destination based on the Resnet backbone, 
                                  domain-general feature, and conditional imitation learning.


## Getting Started

### Dependencies
* Major dependencies
  1. Python 3.7
  2. Pytorch 1.6
  3. cuda 10.2
 
### Installing
* Importing an uploaded Anaconda environment (torch.yaml) is recommended

### Database Acquisition
1. 

### Executing program
* How to run the program
* Step-by-step bullets
```
code blocks for commands
```

## Help

Any advise for common problems or issues.
```
command to run if program contains helper info
```

## Authors

Contributors names and contact info

ex. Dominique Pizzie  
ex. [@DomPizzie](https://twitter.com/dompizzie)

## Version History

* 0.2
    * Various bug fixes and optimizations
    * See [commit change]() or See [release history]()
* 0.1
    * Initial Release

## License

This project is licensed under the [NAME HERE] License - see the LICENSE.md file for details

## Acknowledgments

Inspiration, code snippets, etc.
* [awesome-readme](https://github.com/matiassingers/awesome-readme)
* [PurpleBooth](https://gist.github.com/PurpleBooth/109311bb0361f32d87a2)
* [dbader](https://github.com/dbader/readme-template)
* [zenorocha](https://gist.github.com/zenorocha/4526327)
* [fvcproductions](https://gist.github.com/fvcproductions/1bfc2d4aecb01a834b46)
