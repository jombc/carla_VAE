# Vision based End-to-end autonomous driving using Cycle-consistent VAE
The vision based end-to-end autonomous driving framework for CARLA 0.8 benchmarks.

This repository contains the following modules
 1. Disentanglement_VAE: To disentangling domain-specific feature and domain-general feature from pair images using Cycle-consistent VAE.
 2. starlab_2022: To predict the action values to drive an ego-vehicle to the destination based on the Resnet backbone, 
                                  domain-general feature, and conditional imitation learning.


## Getting Started

### Dependencies
* Major dependencies
  1. Python 3.7
  2. Pytorch 1.6
  3. cuda 10.2
 
### Installing
* Importing an uploaded Anaconda environment (torch.yaml) is recommended

### Database Acquisition
* Method for acquisition of driving data on CARLA simulator is described in this [repository](https://github.com/carla-simulator/data-collector).

### CARLA Simulator and Benchmarks
* You can download from this [document](https://carla.org/2018/04/23/release-0.8.2/).

### Executing program
* How to run the program
* Step-by-step bullets
```
code blocks for commands
```

## Help

Any advise for common problems or issues.
```
command to run if program contains helper info
```

## Authors

Contributors names and contact info

ex. Dominique Pizzie  
ex. [@DomPizzie](https://twitter.com/dompizzie)

## Version History

* 0.2
    * Various bug fixes and optimizations
    * See [commit change]() or See [release history]()
* 0.1
    * Initial Release

## License

This project is licensed under the [NAME HERE] License - see the LICENSE.md file for details

## Acknowledgments

Inspiration, code snippets, etc.
* [awesome-readme](https://github.com/matiassingers/awesome-readme)
* [PurpleBooth](https://gist.github.com/PurpleBooth/109311bb0361f32d87a2)
* [dbader](https://github.com/dbader/readme-template)
* [zenorocha](https://gist.github.com/zenorocha/4526327)
* [fvcproductions](https://gist.github.com/fvcproductions/1bfc2d4aecb01a834b46)
